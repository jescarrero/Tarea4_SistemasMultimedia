{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e4c079-623f-404c-8df1-37fb78b2d5d4",
   "metadata": {},
   "source": [
    "# TAREA 4\n",
    "## Importar librerías y módulos de Python\n",
    "##### Importamos las librerías/módulos específicos de la siguiente forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24230518-7a08-42fe-b027-8bd642ca21de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importacion.\n",
    "# import librosa\n",
    "from scipy.io import wavfile\n",
    "import IPython\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4002c5-2128-4f16-9bd3-ef31cdaed513",
   "metadata": {},
   "source": [
    "## Especificar directorios de entrada y salida\n",
    "##### Aquí definimos los directorios donde guardaremos los audios con los que vamos a trabajar, así como dónde se van a guardar aquellos que generamos a lo largo de la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62693454-e470-4622-9b5e-3276c03d6ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorios que usaremos.\n",
    "cwd = os.getcwd()\n",
    "audio_input_path = os.path.join(cwd, os.path.join('audio', 'examples'))  # cambiar '_input' por 'examples'\n",
    "audio_output_path = os.path.join(cwd, os.path.join('audio', '_output'))\n",
    "print(f'Directorio con los audios de entrada: {audio_input_path}')\n",
    "print(f'Directorio donde guardaremos los audios generados: {audio_output_path}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa10f789-e942-4271-a3b8-d9f2472d56c7",
   "metadata": {},
   "source": [
    "## Cargar el archivo de audio\n",
    "##### Cargamos el archivo de audio .wav en este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657052e8-ac75-418f-a97f-c805f50e165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el archivo de audio.\n",
    "filename = os.path.join(audio_input_path, 'the_last_of_us_reduced.wav')\n",
    "# audio_data, sample_rate = librosa.load(filename, sr=None, mono=False)\n",
    "sample_rate, audio_data = wavfile.read(filename)\n",
    "print(f'Frecuencia de muestreo (sample rate): {sample_rate/1000} kHz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e2c736-512b-4e25-8fea-ad6c1351d249",
   "metadata": {},
   "source": [
    "##### Vamos a escucharlo. Para que esto se haga correctamente, hay que indicarle la frecuencia de muestreo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8169eb1-afc4-4d08-a8ef-cf50cbae71dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(audio_data.T, rate=sample_rate) # .T se pasa únicamente si es audio estéreo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf13b294-8796-4768-bce6-e3a9541622fe",
   "metadata": {},
   "source": [
    "## Conversión de estereo a mono\n",
    "##### Ahora, por simplificación, vamos a calcular la media por canal para obtener un sonido mono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de760240-151e-4aa1-b514-9e149c1bd517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos a mono mediante la media por canal (simplificacion).\n",
    "new_data_mono = audio_data.mean(axis=1)  # Column-wise.\n",
    "# Mantenemos la misma resolucion que antes.\n",
    "new_data_mono = new_data_mono.astype(np.int16)\n",
    "\n",
    "tamaño_bytes = new_data_mono.nbytes  # Tamaño en bytes del array\n",
    "tamaño_mb = tamaño_bytes / (1024 * 1024)\n",
    "print('Nuevos datos de audio (mono):')\n",
    "print(f'Frecuencia de muestreo (sample rate): {sample_rate/1000} kHz')\n",
    "print(f'Número de canales: {new_data_mono[:5]}...')\n",
    "print(f\"El tamaño del audio es: {tamaño_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a63064-9a30-44a0-bab0-6b4796b68e0c",
   "metadata": {},
   "source": [
    "##### Vamos a guardarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2e202a-72ea-4306-b492-e3b63bbfbcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el archivo mono a un fichero de tipo wav.\n",
    "wavfile.write(\n",
    "    filename=os.path.join(audio_output_path, 'the_last_of_us_reduced.wav'),\n",
    "    rate=sample_rate,\n",
    "    data=new_data_mono\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d28b005-4198-466f-af1e-c17186e93c90",
   "metadata": {},
   "source": [
    "##### Vamos a escucharlo de nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4a138-1f24-4797-9949-23c540879205",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(new_data_mono, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6304627b-3203-4fa8-8802-49179e25178b",
   "metadata": {},
   "source": [
    "## Mostrar una gráfica en el tiempo para ambos audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10665055-c4cc-4fa0-917b-a945ec2cb848",
   "metadata": {},
   "outputs": [],
   "source": [
    "ampl_estereo = len(audio_data)\n",
    "ampl_mono = len(new_data_mono)\n",
    "print(f'Número de muestras del audio con fs=48 kHz (valores de amplitud): {ampl_estereo}')\n",
    "print(f'Número de muestras del audio con fs=24 kHz (valores de amplitud): {ampl_mono}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a86bbdb-c7b0-4cf6-aa6f-f50adcc20862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el array para el eje x que representa el tiempo de la grabación.\n",
    "# Tiene la forma: np.arange(Vi, Vf, P).\n",
    "t1 = np.arange(0, ampl_estereo/sample_rate, 1/sample_rate)\n",
    "t2 = np.arange(0, ampl_mono/sample_rate, 1/sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbd378c-33b8-4cde-b8c5-14c56c6d06c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702c3719-4243-42e1-9712-d4f1f4cc4507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la figura.\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "\n",
    "# Solo mostramos las primeras 50 muestras de amplitud (por claridad).\n",
    "end = 50\n",
    "\n",
    "# Señal a 44 kHz.\n",
    "ax[0].plot(t1[:end], audio_data[:end], marker='X')\n",
    "ax[0].set_title(f'Audio en el dominio del tiempo muestreado a {sample_rate} Hz')\n",
    "ax[0].set_ylabel('Amplitud')\n",
    "ax[0].grid(True)\n",
    "\n",
    "# Señal a 44 kHz.\n",
    "# Utilizamos ratio para ajustar el eje x de ambas gráficas\n",
    "# ya que la fs es menor en esta señal.\n",
    "ratio = sample_rate / sample_rate  \n",
    "ax[1].plot(t2[:int(end/ratio)], new_data_mono[:int(end/ratio)], c='tab:red', marker='X')\n",
    "ax[1].set_title(f'Audio en el dominio del tiempo muestreado a {sample_rate} Hz')\n",
    "ax[1].set_xlabel('Tiempo (s)')\n",
    "ax[1].set_ylabel('Amplitud')\n",
    "ax[1].grid(True)\n",
    "\n",
    "# Mostramos la figura.\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34093f0c-632c-4693-9afb-76310e9fc97e",
   "metadata": {},
   "source": [
    "## Explicación\n",
    "### Ahora se va a explicar que es recuencia de muestreo, aliasing, profundidad de bits, ancho de banda y tasa de bits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bf4c93-ed2b-48a0-bc7d-491d8e3327eb",
   "metadata": {},
   "source": [
    "##### - Frecuencia de muestreo: Es el número de muestras que se toman por segundo de una señal analógica para convertirla en digital. Una mayor frecuencia captura más detalles del sonido.\n",
    "\n",
    "##### - Aliasing: Es un error que ocurre cuando la frecuencia de muestreo es demasiado baja y las altas frecuencias se \"confunden\" con frecuencias más bajas, generando distorsión en la señal digital.\n",
    "\n",
    "##### - Profundidad de bits: Es la cantidad de bits usados para representar cada muestra. Mayor profundidad permite una representación más precisa del audio, ofreciendo un mayor rango dinámico y menor ruido.\n",
    "\n",
    "##### - Ancho de banda: Es el rango de frecuencias que una señal puede transmitir o reproducir. En audio, define la cantidad de información sonora que se puede captar y reproducir.\n",
    "\n",
    "##### - Tasa de bits: Es la cantidad de datos (en bits) procesados o transmitidos por segundo. Se relaciona con la calidad del audio y se calcula multiplicando la frecuencia de muestreo, la profundidad de bits y el número de canales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a27c1dc-4694-4920-a012-554b5a656882",
   "metadata": {},
   "source": [
    "## Transformada de Fourier para el audio mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f893e84e-8e73-48ff-b240-a0ef683d7f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La longitud del array de datos y el\n",
    "# sample rate (frecuencia de muestreo).\n",
    "n = len(new_data_mono)\n",
    "Fs = sample_rate\n",
    "\n",
    "# Working with mono audio, there are one channel in the audio data.\n",
    "# Let's retrieve each channel seperately:\n",
    "# ch1 = np.array([data[i][0] for i in range(n)]) #channel 1\n",
    "# We can then perform a Fourier analysis on the first\n",
    "# channel to see what the spectrum looks like.\n",
    "\n",
    "# Calculando la Transformada Rapida de Fourier (FFT) en audio mono.\n",
    "ch_Fourier = np.fft.fft(new_data_mono)  # ch1\n",
    "\n",
    "# Solo miramos frecuencia por debajo de Fs/2\n",
    "# (Nyquist-Shannon) --> Spectrum.\n",
    "abs_ch_Fourier = np.absolute(ch_Fourier[:n//2])\n",
    "\n",
    "# Graficamos.\n",
    "plt.plot(np.linspace(0, Fs/2, n//2), abs_ch_Fourier)\n",
    "plt.ylabel('Amplitud', labelpad=10)\n",
    "plt.xlabel('$f$ (Hz)', labelpad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eea0894-7f3d-4210-85c6-de1e74fcd173",
   "metadata": {},
   "source": [
    "### Por qué se aplica la FFT y qué muestra la gráfica\n",
    "##### Transformada Rápida de Fourier (FFT): Permite pasar la señal del dominio del tiempo (amplitud vs. muestras/tiempo) al dominio de la frecuencia (amplitud vs. frecuencias).\n",
    "##### Dominio de la frecuencia: Muestra en qué frecuencias está concentrada la energía de la señal. Los picos indican las componentes de mayor amplitud (por ejemplo, graves, medios o agudos).\n",
    "##### Por qué la mitad del espectro: Para señales de audio mono (reales), la FFT es simétrica en torno a la frecuencia 0, por lo que basta graficar hasta sample_rate/2 (Nyquist).\n",
    "##### Interpretación: Con esta gráfica se puede identificar las zonas donde el audio tiene más potencia (por ejemplo, un pico fuerte en frecuencias bajas si hay mucho contenido grave). En música o voz, gran parte de la energía se concentra en rangos de frecuencias específicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0683af30-bd65-46d2-8cf4-c40261c9f6cd",
   "metadata": {},
   "source": [
    "## Energia del espectrograma y frecuencia de corte\n",
    "##### Ahora vamos a definir una frecuencia umbral por la que cortar el espectro, es decir, solo nos quedaremos con aquellas frecuencias que esten por debajo de este valor para el archivo de audio comprimido.\n",
    "##### Con este fin, definimos el parámetro epsilon que representa la parte de la energía del espectro que NO conservaremos (la integral con respecto a la frecuencia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518ff2c4-fa00-45e0-99e2-a156eef725ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos diferentes epsilons: la parte de\n",
    "# la energia del espectro que NO conservamos.\n",
    "eps = [1e-5, .02, .041, .063, .086, .101, .123]\n",
    "\n",
    "# Jugamos con los valores de epsilon (ID VARIANDO ESTE VALOR Y MIRAD LA GRÁFICA).\n",
    "eps = eps[2]\n",
    "print(f'Epsilon: {eps}')\n",
    "\n",
    "# Calculamos el valor de corte para esta energia.\n",
    "thr_spec_energy = (1 - eps) * np.sum(abs_ch_Fourier)\n",
    "print(f'Valor de corte para la energia del espectro: {thr_spec_energy}')\n",
    "\n",
    "# Integral de la frecuencia --> energia del espectro.\n",
    "spec_energy = np.cumsum(abs_ch_Fourier)\n",
    "\n",
    "# Mascara (array booleano) que compara el\n",
    "# valor de corte con la energia del espectro.\n",
    "frequencies_to_remove = thr_spec_energy < spec_energy  \n",
    "print(f'Mascara: {frequencies_to_remove}')\n",
    "\n",
    "# La frecuencia f0 por la que cortamos el espectro.\n",
    "f0 = (len(frequencies_to_remove) - np.sum(frequencies_to_remove)) * (Fs/2) / (n//2)\n",
    "print(f'Frecuencia de corte f0 (Hz): {int(f0)}')\n",
    "\n",
    "# Graficamos.\n",
    "plt.axvline(f0, color='r')\n",
    "plt.plot(np.linspace(0, Fs/2, n//2), abs_ch_Fourier)\n",
    "plt.ylabel('Amplitud')\n",
    "plt.xlabel('$f$ (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffc70d4-a529-43e5-99f2-5e72ccfc12e7",
   "metadata": {},
   "source": [
    "##### He seleccionado un valor de epsilon = 0.041. Esto significa que se descarta aproximadamente el 4.1% de la energía total del espectro y se conserva el 95.9% restante. He optado por este valor porque logra eliminar componentes de muy baja energía—posiblemente ruido—mientras se mantienen intactas las características principales de la señal, obteniendo así un espectro más limpio y representativo del audio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dffb95a-d429-472a-9c38-9830fd345edd",
   "metadata": {},
   "source": [
    "## Comprensión del archivo\n",
    "### Reducción de la resolución de muestreo (downsampling)\n",
    "##### Para reducir el tamaño del archivo de audio, lo que vamos a hacer es aplicar downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6f393d-880b-4004-a5ca-26a6248609cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el factor D de downsampling.\n",
    "D = int(Fs / f0)\n",
    "print(f'Factor de downsampling: {D}')\n",
    "\n",
    "# Obtenemos los nuevos datos (slicing with stride).\n",
    "new_data = new_data_mono[::D]\n",
    "\n",
    "# Definimos el nombre del audio comprimido generado.\n",
    "wav_compressed_file = \"the_last_of_us_compressed.wav\"\n",
    "\n",
    "# Escribimos los datos a un archivo de tipo wav.\n",
    "wavfile.write(\n",
    "    filename=os.path.join(audio_output_path, wav_compressed_file),\n",
    "    rate=int(Fs/D),\n",
    "    data=new_data\n",
    ")\n",
    "\n",
    "# Cargamos el nuevo archivo.\n",
    "new_sample_rate, new_audio_data = wavfile.read(filename=os.path.join(audio_output_path, wav_compressed_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1378e427-5d45-4f2b-b3da-1dac0aa94237",
   "metadata": {},
   "source": [
    "##### Vamos a escucharlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77606dcb-c939-40ab-b6f1-8c30d887199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(new_audio_data, rate=new_sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d04d1f5-b625-4481-aea1-c4d627854612",
   "metadata": {},
   "source": [
    "## Espectograma de ambas ondas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07769f3-d317-43b5-bb9b-e5edb1ec3b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "Pxx, freqs, bins, im = ax[0].specgram(new_data_mono, NFFT=1024, Fs=sample_rate, noverlap=512)\n",
    "ax[0].set_title('Espectograma del audio original')\n",
    "ax[0].set_ylabel('Frecuencia (Hz)')\n",
    "ax[0].grid(True)\n",
    "\n",
    "Pxx, freqs, bins, im = ax[1].specgram(new_audio_data, NFFT=1024, Fs=new_sample_rate, noverlap=512)\n",
    "ax[1].set_title('Espectrograma del audio reducido/comprimido')\n",
    "ax[1].set_xlabel('Tiempo (s)')\n",
    "ax[1].set_ylabel('Frecuencia (Hz)')\n",
    "ax[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a671db27-5f36-447d-bf22-6dc47c732042",
   "metadata": {},
   "source": [
    "##### En el espectrograma original, se ve un rango amplio de frecuencias hasta la parte alta (zonas amarillas y verdes más arriba). En cambio, en el espectrograma comprimido, las frecuencias más altas casi desaparecen, porque hemos recortado (o reducido) la señal a una banda de frecuencias menor. Esto hace que el archivo sea más pequeño, pero perdemos parte de los sonidos agudos, y se nota menos “brillo” en la música."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b398763e-4366-426e-a25c-14e978b64157",
   "metadata": {},
   "source": [
    "## Tamaño de los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab6dec-dee7-4f50-a67c-3b287b23e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -sh audio/_output/the_last_of_us_compressed.wav\n",
    "!ls -sh audio/_output/the_last_of_us_reduced.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e0d711-490a-4ac3-b402-624ac5816348",
   "metadata": {},
   "source": [
    "## Reproducción de los archivos de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e02060-a803-4731-9c92-57e15cd9b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(new_data_mono, rate=sample_rate) # Audio original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deddc6d8-8dda-472f-a423-63b63115fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(new_audio_data, rate=new_sample_rate) # Audio comprimido"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (audiopy)",
   "language": "python",
   "name": "audiopy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
